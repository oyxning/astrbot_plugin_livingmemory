# -*- coding: utf-8 -*-
"""
recall_engine.py - å›å¿†å¼•æ“
è´Ÿè´£æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼Œä½¿ç”¨å¤šç­–ç•¥æ™ºèƒ½å¬å›æœ€ç›¸å…³çš„è®°å¿†ã€‚
æ”¯æŒå¯†é›†å‘é‡æ£€ç´¢ã€ç¨€ç–æ£€ç´¢å’Œæ··åˆæ£€ç´¢ã€‚
"""

import json
import math
from typing import List, Dict, Any, Optional

from astrbot.api import logger
from astrbot.api.star import Context
from ...storage.faiss_manager import FaissManager, Result
from ..retrieval import SparseRetriever, ResultFusion, SearchResult
from ..utils import get_now_datetime


class RecallEngine:
    """
    å›å¿†å¼•æ“ï¼šè´Ÿè´£æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼Œä½¿ç”¨å¤šç­–ç•¥æ™ºèƒ½å¬å›æœ€ç›¸å…³çš„è®°å¿†ã€‚
    æ”¯æŒå¯†é›†å‘é‡æ£€ç´¢ã€ç¨€ç–æ£€ç´¢å’Œæ··åˆæ£€ç´¢ã€‚
    """

    def __init__(self, config: Dict[str, Any], faiss_manager: FaissManager, sparse_retriever: Optional[SparseRetriever] = None):
        """
        åˆå§‹åŒ–å›å¿†å¼•æ“ã€‚

        Args:
            config (Dict[str, Any]): æ’ä»¶é…ç½®ä¸­ 'recall_engine' éƒ¨åˆ†çš„å­—å…¸ã€‚
            faiss_manager (FaissManager): æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹ã€‚
            sparse_retriever (Optional[SparseRetriever]): ç¨€ç–æ£€ç´¢å™¨å®ä¾‹ã€‚
        """
        self.config = config
        self.faiss_manager = faiss_manager
        self.sparse_retriever = sparse_retriever

        # åˆå§‹åŒ–ç»“æœèåˆå™¨
        fusion_config = config.get("fusion", {})
        fusion_strategy = fusion_config.get("strategy", "rrf")
        self.result_fusion = ResultFusion(strategy=fusion_strategy, config=fusion_config)

        # è®°å½•é…ç½®ä¿¡æ¯
        retrieval_mode = config.get("retrieval_mode", "hybrid")
        top_k = config.get("top_k", 5)
        logger.info(f"RecallEngine åˆå§‹åŒ–æˆåŠŸ")
        logger.info(f"  æ£€ç´¢æ¨¡å¼: {retrieval_mode}")
        logger.info(f"  é»˜è®¤è¿”å›æ•°é‡: {top_k}")
        logger.info(f"  èåˆç­–ç•¥: {fusion_strategy}")
        logger.info(f"  ç¨€ç–æ£€ç´¢å™¨: {'å·²å¯ç”¨' if sparse_retriever else 'æœªå¯ç”¨'}")

    async def recall(
        self,
        context: Context,
        query: str,
        session_id: Optional[str] = None,
        persona_id: Optional[str] = None,
        k: Optional[int] = None,
    ) -> List[Result]:
        """
        æ‰§è¡Œå›å¿†æµç¨‹ï¼Œæ£€ç´¢å¹¶å¯èƒ½é‡æ’è®°å¿†ã€‚

        Args:
            query (str): ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬ã€‚
            session_id (Optional[str], optional): å½“å‰ä¼šè¯ ID. Defaults to None.
            persona_id (Optional[str], optional): å½“å‰äººæ ¼ ID. Defaults to None.
            k (Optional[int], optional): å¸Œæœ›è¿”å›çš„è®°å¿†æ•°é‡ï¼Œå¦‚æœä¸º None åˆ™ä»é…ç½®ä¸­è¯»å–.

        Returns:
            List[Result]: æœ€ç»ˆè¿”å›ç»™ä¸Šå±‚åº”ç”¨çš„è®°å¿†åˆ—è¡¨ã€‚
        """
        top_k = k if k is not None else self.config.get("top_k", 5)
        retrieval_mode = self.config.get("retrieval_mode", "hybrid")  # hybrid, dense, sparse

        logger.info(f"ğŸ” å¼€å§‹å¬å›è®°å¿†")
        logger.debug(f"  æŸ¥è¯¢å†…å®¹: {query[:100]}{'...' if len(query) > 100 else ''}")
        logger.debug(f"  æ£€ç´¢æ¨¡å¼: {retrieval_mode}")
        logger.debug(f"  ç›®æ ‡æ•°é‡: {top_k}")
        logger.debug(f"  ä¼šè¯ID: {session_id or 'æ— '}")
        logger.debug(f"  äººæ ¼ID: {persona_id or 'æ— '}")

        # åˆ†ææŸ¥è¯¢ç‰¹å¾ï¼ˆç”¨äºè‡ªé€‚åº”ç­–ç•¥ï¼‰
        query_info = self.result_fusion.analyze_query(query)
        logger.debug(f"  æŸ¥è¯¢åˆ†æ: é•¿åº¦={query_info.get('length', 0)}, å…³é”®è¯æ•°={len(query_info.get('keywords', []))}")

        try:
            # æ ¹æ®æ£€ç´¢æ¨¡å¼æ‰§è¡Œæœç´¢
            if retrieval_mode == "hybrid" and self.sparse_retriever:
                # æ··åˆæ£€ç´¢
                logger.info("ğŸ“Š ä½¿ç”¨æ··åˆæ£€ç´¢æ¨¡å¼ (å¯†é›†å‘é‡ + ç¨€ç–å…³é”®è¯)")
                results = await self._hybrid_search(context, query, session_id, persona_id, top_k, query_info)
            elif retrieval_mode == "sparse" and self.sparse_retriever:
                # çº¯ç¨€ç–æ£€ç´¢
                logger.info("ğŸ”¤ ä½¿ç”¨ç¨€ç–æ£€ç´¢æ¨¡å¼ (BM25)")
                results = await self._sparse_search(query, session_id, persona_id, top_k)
            else:
                # çº¯å¯†é›†æ£€ç´¢ï¼ˆé»˜è®¤ï¼‰
                logger.info("ğŸ¯ ä½¿ç”¨å¯†é›†æ£€ç´¢æ¨¡å¼ (å‘é‡ç›¸ä¼¼åº¦)")
                results = await self._dense_search(context, query, session_id, persona_id, top_k)

            logger.info(f"âœ… å¬å›å®Œæˆï¼Œè¿”å› {len(results)} æ¡è®°å¿†")
            if results:
                logger.debug(f"  æœ€é«˜ç›¸ä¼¼åº¦: {results[0].similarity:.3f}")
                logger.debug(f"  æœ€ä½ç›¸ä¼¼åº¦: {results[-1].similarity:.3f}")

            return results

        except Exception as e:
            logger.error(f"âŒ å¬å›è®°å¿†æ—¶å‘ç”Ÿé”™è¯¯: {type(e).__name__}: {e}", exc_info=True)
            logger.error(f"  é”™è¯¯ä¸Šä¸‹æ–‡: query='{query[:50]}...', mode={retrieval_mode}, k={top_k}")
            return []

    async def _hybrid_search(
        self,
        context: Context,
        query: str,
        session_id: Optional[str],
        persona_id: Optional[str],
        k: int,
        query_info: Dict[str, Any]
    ) -> List[Result]:
        """æ‰§è¡Œæ··åˆæ£€ç´¢"""
        logger.debug(f"æ··åˆæ£€ç´¢: ç›®æ ‡æ•°é‡={k}, æ¯è·¯æ£€ç´¢={k*2}")

        # å¹¶è¡Œæ‰§è¡Œå¯†é›†å’Œç¨€ç–æ£€ç´¢
        import asyncio

        try:
            # å¯†é›†æ£€ç´¢
            logger.debug("  å¯åŠ¨å¯†é›†æ£€ç´¢ä»»åŠ¡...")
            dense_task = self.faiss_manager.search_memory(
                query=query, k=k*2, session_id=session_id, persona_id=persona_id
            )

            # ç¨€ç–æ£€ç´¢
            logger.debug("  å¯åŠ¨ç¨€ç–æ£€ç´¢ä»»åŠ¡...")
            sparse_task = self.sparse_retriever.search(
                query=query, limit=k*2, session_id=session_id, persona_id=persona_id
            )

            # ç­‰å¾…ä¸¤ä¸ªæ£€ç´¢å®Œæˆ
            dense_results, sparse_results = await asyncio.gather(dense_task, sparse_task, return_exceptions=True)

            # å¤„ç†å¼‚å¸¸
            if isinstance(dense_results, Exception):
                logger.error(f"âŒ å¯†é›†æ£€ç´¢å¤±è´¥: {type(dense_results).__name__}: {dense_results}")
                dense_results = []
            else:
                logger.debug(f"  å¯†é›†æ£€ç´¢è¿”å›: {len(dense_results)} æ¡ç»“æœ")

            if isinstance(sparse_results, Exception):
                logger.error(f"âŒ ç¨€ç–æ£€ç´¢å¤±è´¥: {type(sparse_results).__name__}: {sparse_results}")
                sparse_results = []
            else:
                logger.debug(f"  ç¨€ç–æ£€ç´¢è¿”å›: {len(sparse_results)} æ¡ç»“æœ")

            if not dense_results and not sparse_results:
                logger.warning("âš ï¸ æ··åˆæ£€ç´¢ä¸¤è·¯å‡æ— ç»“æœ")
                return []

            # èåˆç»“æœ
            logger.debug(f"  å¼€å§‹èåˆç»“æœï¼Œç­–ç•¥: {self.result_fusion.strategy}")
            fused_results = self.result_fusion.fuse(
                dense_results=dense_results,
                sparse_results=sparse_results,
                k=k,
                query_info=query_info
            )
            logger.debug(f"  èåˆå®Œæˆï¼Œè¿”å› {len(fused_results)} æ¡ç»“æœ")

            # è½¬æ¢å› Result æ ¼å¼
            final_results = []
            for result in fused_results:
                final_results.append(Result(
                    data={
                        "id": result.doc_id,
                        "text": result.content,
                        "metadata": result.metadata
                    },
                    similarity=result.final_score
                ))

            # åº”ç”¨ä¼ ç»Ÿçš„åŠ æƒé‡æ’ï¼ˆå¦‚æœéœ€è¦ï¼‰
            strategy = self.config.get("recall_strategy", "weighted")
            if strategy == "weighted":
                logger.debug("  åº”ç”¨åŠ æƒé‡æ’ (ç›¸ä¼¼åº¦+é‡è¦æ€§+æ–°è¿‘åº¦)...")
                final_results = self._rerank_by_weighted_score(context, final_results)
                logger.debug(f"  é‡æ’å®Œæˆï¼Œæœ€ç»ˆè¿”å› {len(final_results)} æ¡ç»“æœ")

            return final_results

        except Exception as e:
            logger.error(f"âŒ æ··åˆæ£€ç´¢è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {e}", exc_info=True)
            return []

    async def _dense_search(
        self,
        context: Context,
        query: str,
        session_id: Optional[str],
        persona_id: Optional[str],
        k: int
    ) -> List[Result]:
        """æ‰§è¡Œå¯†é›†æ£€ç´¢"""
        logger.debug(f"å¯†é›†æ£€ç´¢: k={k}")

        try:
            results = await self.faiss_manager.search_memory(
                query=query, k=k, session_id=session_id, persona_id=persona_id
            )

            if not results:
                logger.debug("  å¯†é›†æ£€ç´¢æ— ç»“æœ")
                return []

            logger.debug(f"  å¯†é›†æ£€ç´¢è¿”å› {len(results)} æ¡ç»“æœ")

            # åº”ç”¨é‡æ’
            strategy = self.config.get("recall_strategy", "weighted")
            if strategy == "weighted":
                logger.debug("  åº”ç”¨åŠ æƒé‡æ’ (ç›¸ä¼¼åº¦+é‡è¦æ€§+æ–°è¿‘åº¦)...")
                reranked = self._rerank_by_weighted_score(context, results)
                logger.debug(f"  é‡æ’å®Œæˆï¼Œè¿”å› {len(reranked)} æ¡ç»“æœ")
                return reranked
            else:
                logger.debug(f"  ä½¿ç”¨ '{strategy}' ç­–ç•¥ï¼Œç›´æ¥è¿”å›åŸå§‹ç»“æœ")
                return results

        except Exception as e:
            logger.error(f"âŒ å¯†é›†æ£€ç´¢è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {e}", exc_info=True)
            return []

    async def _sparse_search(
        self,
        query: str,
        session_id: Optional[str],
        persona_id: Optional[str],
        k: int
    ) -> List[Result]:
        """æ‰§è¡Œç¨€ç–æ£€ç´¢"""
        logger.debug(f"ç¨€ç–æ£€ç´¢: k={k}")

        try:
            sparse_results = await self.sparse_retriever.search(
                query=query, limit=k, session_id=session_id, persona_id=persona_id
            )

            if not sparse_results:
                logger.debug("  ç¨€ç–æ£€ç´¢æ— ç»“æœ")
                return []

            logger.debug(f"  ç¨€ç–æ£€ç´¢è¿”å› {len(sparse_results)} æ¡ç»“æœ")

            # è½¬æ¢ä¸º Result æ ¼å¼
            results = []
            for result in sparse_results:
                results.append(Result(
                    data={
                        "id": result.doc_id,
                        "text": result.content,
                        "metadata": result.metadata
                    },
                    similarity=result.score
                ))

            return results

        except Exception as e:
            logger.error(f"âŒ ç¨€ç–æ£€ç´¢è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {e}", exc_info=True)
            return []

    def _rerank_by_weighted_score(
        self, context: Context, results: List[Result]
    ) -> List[Result]:
        """
        æ ¹æ®ç›¸ä¼¼åº¦ã€é‡è¦æ€§å’Œæ–°è¿‘åº¦å¯¹ç»“æœè¿›è¡ŒåŠ æƒé‡æ’ã€‚
        """
        sim_w = self.config.get("similarity_weight", 0.6)
        imp_w = self.config.get("importance_weight", 0.2)
        rec_w = self.config.get("recency_weight", 0.2)

        reranked_results = []
        current_time = get_now_datetime(context).timestamp()

        for res in results:
            # å®‰å…¨è§£æå…ƒæ•°æ®
            metadata = res.data.get("metadata", {})
            if isinstance(metadata, str):
                try:
                    metadata = json.loads(metadata)
                except json.JSONDecodeError as e:
                    logger.warning(f"è§£æè®°å¿†å…ƒæ•°æ®å¤±è´¥: {e}")
                    metadata = {}

            # å½’ä¸€åŒ–å„é¡¹å¾—åˆ† (0-1)
            similarity_score = res.similarity
            importance_score = metadata.get("importance", 0.0)

            # è®¡ç®—æ–°è¿‘åº¦å¾—åˆ†
            last_access = metadata.get("last_access_time", current_time)
            # å¢åŠ å¥å£®æ€§æ£€æŸ¥ï¼Œä»¥é˜² last_access æ˜¯å­—ç¬¦ä¸²
            if isinstance(last_access, str):
                try:
                    last_access = float(last_access)
                except (ValueError, TypeError):
                    last_access = current_time

            hours_since_access = (current_time - last_access) / 3600
            # ä½¿ç”¨æŒ‡æ•°è¡°å‡ï¼ŒåŠè¡°æœŸçº¦ä¸º24å°æ—¶
            recency_score = math.exp(-0.028 * hours_since_access)

            # è®¡ç®—æœ€ç»ˆåŠ æƒåˆ†
            final_score = (
                similarity_score * sim_w
                + importance_score * imp_w
                + recency_score * rec_w
            )

            # ç›´æ¥ä¿®æ”¹ç°æœ‰ Result å¯¹è±¡çš„ similarity åˆ†æ•°
            res.similarity = final_score
            reranked_results.append(res)

        # æŒ‰æœ€ç»ˆå¾—åˆ†é™åºæ’åº
        reranked_results.sort(key=lambda x: x.similarity, reverse=True)

        return reranked_results
